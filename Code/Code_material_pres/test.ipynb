{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74    113064\n",
      "           1       0.09      0.44      0.15      9941\n",
      "\n",
      "    accuracy                           0.60    123005\n",
      "   macro avg       0.51      0.52      0.44    123005\n",
      "weighted avg       0.86      0.60      0.69    123005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "path_application_train = \"/home/dark/VS-CodePythonProjects/DataScience-Club/Credit-Risk-Model/Data/application_train.csv\"\n",
    "df = pd.read_csv(path_application_train)\n",
    "\n",
    "# Figuring out the missing values\n",
    "\n",
    "miss_val = df.isnull().sum()\n",
    "miss_val_perc = 100 * df.isnull().sum() / len(df)\n",
    "greater_0 = miss_val_perc[miss_val_perc != 0].round(2)\n",
    "greater_0 = greater_0.sort_values(ascending=False)\n",
    "list_col = greater_0.index.to_list()\n",
    "df = df.drop(columns=list_col)\n",
    "\n",
    "\n",
    "\n",
    "missing_threshold = 0.5\n",
    "missing_perc = df.isnull().mean()\n",
    "\n",
    "cols_to_drop = missing_perc[missing_perc > missing_threshold].index\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "cols_to_drop = ['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
    "                'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13',\n",
    "                'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "                'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'ORGANIZATION_TYPE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE',\n",
    "                'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'REGION_POPULATION_RELATIVE', 'DAYS_REGISTRATION', 'REGION_RATING_CLIENT',\n",
    "                'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY']\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "df = df.select_dtypes(exclude='object')\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), PoissonRegressor())\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96    113014\n",
      "           1       0.25      0.02      0.04      9991\n",
      "\n",
      "    accuracy                           0.92    123005\n",
      "   macro avg       0.59      0.51      0.50    123005\n",
      "weighted avg       0.87      0.92      0.88    123005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm\n",
    "\n",
    "path_application_train = \"/home/dark/VS-CodePythonProjects/DataScience-Club/Credit-Risk-Model/Data/application_train.csv\"\n",
    "df = pd.read_csv(path_application_train)\n",
    "\n",
    "# Figuring out the missing values\n",
    "miss_val = df.isnull().sum()\n",
    "miss_val_perc = 100 * miss_val / len(df)\n",
    "missing_threshold = 0.9\n",
    "cols_to_drop = miss_val_perc[miss_val_perc > missing_threshold].index\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
    "                'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13',\n",
    "                'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "                'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'ORGANIZATION_TYPE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE',\n",
    "                'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'REGION_POPULATION_RELATIVE', 'DAYS_REGISTRATION', 'REGION_RATING_CLIENT',\n",
    "                'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY']\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "df = df.select_dtypes(exclude='object')\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_resampled = sm.add_constant(X_train_resampled)\n",
    "\n",
    "glm_model = sm.GLM(y_train_resampled, X_train_resampled, family=sm.families.Binomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "X_test_with_const = sm.add_constant(X_test)\n",
    "y_pred = glm_results.predict(X_test_with_const)\n",
    "\n",
    "\n",
    "y_pred_binary = (y_pred >= 0.9).astype(int)\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9195161211648212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dark/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Modelling - Default Risk Prediction\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "Credit Risk itself is a very broad topic and has a lot of different approaches, as talked about in the earlier slides, We will use Generalised Linear Models (GLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here import libraries\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
